{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = train_images.reshape((60000, 28*28))\n",
    "# now unrolled\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = train_images.astype('float32') / 255\n",
    "train_images[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is creating our vectorized output, so that the last layer of the network can \n",
    "# compare to a vector\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 1.4845 - accuracy: 0.6583\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.5933 - accuracy: 0.8520\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.4134 - accuracy: 0.8878\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.3538 - accuracy: 0.9006\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.3245 - accuracy: 0.9078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1282f1668>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the network\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 36us/step\n",
      "test accuracy: 0.819599986076355\n"
     ]
    }
   ],
   "source": [
    "# get test set metrics\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print(\"test accuracy: {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() \n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "digit = train_images[4565]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, :, :]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, :28, :28]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3, 32, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# broadcasting\n",
    "# smaller tensor is broadcast to become the shape of larger tensor by:\n",
    "# 1. adding axes to smaller tensor to match ndim of larger\n",
    "# 2. smaller tensor is repeated alongside new axes to match new shape (larger tensor)\n",
    "\n",
    "x = np.random.random((64,3,32,10))\n",
    "y = np.random.random((32, 10))\n",
    "\n",
    "z = x + y\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape((160,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 160)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(y).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
